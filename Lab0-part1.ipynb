{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOov38GHs6zw6DXFloI7hVd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. Installing PySpark in Google Colab"],"metadata":{"id":"ZE5FExCYe8ax"}},{"cell_type":"markdown","source":["Install Dependencies (needs to be done once each time you re-open this notebook):\n","\n","1.   Java 8\n","2.   Apache Spark with hadoop and\n","3.   Findspark (used to locate the spark in the system)"],"metadata":{"id":"pei0I5IYf4xd"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"1cJjMt8Aeb9J","executionInfo":{"status":"ok","timestamp":1732765175114,"user_tz":-480,"elapsed":38183,"user":{"displayName":"Evelyn Chee","userId":"03637392660163232340"}}},"outputs":[],"source":["# install java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# install spark (change the version number if needed)\n","!wget -q https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n","\n","# unzip the spark file to the current folder\n","!tar xf spark-3.5.3-bin-hadoop3.tgz\n","\n","# set your spark folder to your system path environment.\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\"\n","\n","# install findspark using pip\n","!pip install -q findspark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"]},{"cell_type":"markdown","source":["# 1. Wordcount"],"metadata":{"id":"0eOTJa-R08yZ"}},{"cell_type":"code","source":["import sys, os\n","if 'google.colab' in sys.modules:\n","    # find automatically the path of the folder containing \"file_name\" :\n","    file_name = 'Lab0-part1.ipynb'\n","    import subprocess\n","    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n","    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n","    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n","    #path_to_file = '/content/gdrive/My Drive/CS5344_AY2425Sem2_Lab'\n","    print(path_to_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lu4BPD7p1zH-","executionInfo":{"status":"ok","timestamp":1732765210740,"user_tz":-480,"elapsed":598,"user":{"displayName":"Evelyn Chee","userId":"03637392660163232340"}},"outputId":"c19ed4da-91bc-479a-eaa0-646632eee0ed"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["./gdrive/MyDrive/CS5344_Lab/CS5344_AY2425Sem2_Lab/\n"]}]},{"cell_type":"code","source":["import re\n","\n","sc = spark.sparkContext\n","\n","lines = sc.textFile(f'{path_to_file}/Lab0_part1_in.txt')\n","words = lines.flatMap(lambda l: re.split(r'[^\\w]+',l))\n","pairs = words.map(lambda w: (w, 1))\n","counts = pairs.reduceByKey(lambda n1, n2: n1 + n2)\n","\n","print(counts.take(5))\n","\n","counts.repartition(1).saveAsTextFile(f'{path_to_file}/Lab0_part1_out')\n","sc.stop()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1vBqmUael9O","executionInfo":{"status":"ok","timestamp":1732765228649,"user_tz":-480,"elapsed":9716,"user":{"displayName":"Evelyn Chee","userId":"03637392660163232340"}},"outputId":"6288416b-87da-443e-f00f-34932287475c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[('are', 2), ('as', 8), ('look', 1), ('', 4), ('walk', 1)]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"iQHpjBZxjW9S"},"execution_count":null,"outputs":[]}]}